[
["index.html", "A gentle Introduction of Coding with R Preface", " A gentle Introduction of Coding with R Masumbuko Semba 2018-11-19 Preface We live in an age where data generated and collected in a fraction of a minute is enormous. To get insight out of these data they must analysed. Several tools have been developed to tacke the issue of data and obtain knowledge out of this digital data age. One of the tools is the R programming language, which has increased recently and become a one-stop solution to data problem. In this book, I introduce to the readers some of the useful packages and tools in R that are commonly used to handle and tranform data and produce elegant graphics with R programming language. The book talks about coding using R programming languages. Coding is nothing more than telling a computer what to do in a language the computer understands. Learning to code will help you to develop critical thinking skills and ability to solve problems. We will cover various analytical processes and methods that will help reader to apply them to analyse their own datasets. "],
["prerequisities.html", "Prerequisities", " Prerequisities I developed this book with a focus to readers who are unfamiliar with statistical analysis and coding. I tried to make it as simple as posssible to provide the background of underlaying statistics to provide a glimpse of the theory behind statistical concepts. Because the book use R, I will take through each step in R so that the reader get familiar with this powerful programming language. — Masumbuko Semba "],
["resources.html", "Resources", " Resources Here is a list of resources that make you up and running in R. I will keep adding the list whenever I find a resourceful document floating online. A Sufficient Introduction to R UC Business Analytics R Programming Guide graphics with ggplot2 ggplot graphics Beautiful plotting in R with ggplot2 The definitive guide of Rmarkdown bookdownplus "],
["why-programming.html", "Chapter 1 Why Programming? 1.1 Learning to program 1.2 Programming in R", " Chapter 1 Why Programming? The benefit of learning to program are numerous. Programming makes data-analysis more efficient, accurate and transparent—opens new doors for new analyses that would not be practical or possible without programming. Most experiments for instance are often carried out on computers, so programming is vital for designing, creating and implementing experiments. The advent in computer technology plays an important role in research, and there are many kinds of proprietary softwared developed specifically to deal with data ana anlysis in research. For example most statistians and researchers analyse their data with using proprietary software like Microsoft Excel, SPSS, SAS and many others. These kind of canned software are widely used and useful. They are generally user-friendely with graphic user interface (GUI)1 require lillte or no programming knowledge, and you can complete analytical tasks in relatively small amount of time. Unfortunate the click-and drag interface you interact with in the GUI is a result of code hidden to user with these software. So you can only accomplish the taks based on how the software is program to do and incapable of doing some task that it was not designed for. You will sometimes find that the software is simply incapable of doing a particular kind of statistical anlysis or running a particular kind of experiment. At that juncture, it becomes apparent for researcher and scientists to learn programming, which help to solve solutions to unique and emerging research problems directly. Learning how to program and create your own code allows control over every detail of analyzing data. This level of control is invaluable for creating flexible and customizable data analysis, and for being confident in the output that decision makers depends. Another advantage of learning to program worth mentioning is time-saving. Becoming fluent in programming enables you to handle research data in relatively short time. This is because with programming language skills, you automate most of the tasks with scripts or code, which save you copious amounts of time in analysing your data and open new way of exploring and visualizing the data you are working on. This make you understand the data in a different way. Finally, computer programming is a valuable skill in general and may open doors in the larger workforce in this digital age. 1.1 Learning to program Learning programming is a skill and requires an initial investment. It takes practice, time, and effort. There is no easy way out. There are many layers to individual programming languages, and there are many programming languages out there to learn that could be useful. Befere you begin to learn to code, it is important to recognize that the underlying skill of computer programming is problem-solving—the ability to sovle new problem yourself with computer. From the perspective of applying computer programming techniques to solve problems in science and other fields, theae are three major aspects. These are: Understaing the issues that need to be addressed Understanding the tools available at your disposal Applying the tools to solve the problem In most cases people know the issues and want to solve them problems, the biggest and vital componet that is often missing are the tools. Recognize the tools is one way but understand how to use the tools to the solve the proleme is the most difficult step. This is what they call the chicken and egg problem. What should you learn first? Should you learn about how organize codes at the beginning or after you have learn some basic aspects of the language? Should you learn random tidbits of programming languages before learning how to apply those tidbits to solve a problem? This is a dilemma for most of us, because we real unsure of the base and where to start. The major porting of this book will deal with the understanding the tool— the basic building blocks of any programming languages. Fortunate, most programming languages use the same basci concept forming the building bloacks for making all sort of programs. However, this book will specifically focus on R language. We believe that iving examples codes will make you understand the tools available to you and this has spill over effect as it will help you to: understand the conceptual tools write codes to implement the tools using the specific syntax2 to solve the problems or address the issues you are facing. Coding is writing a recipe for solving a problem. More specifically, it is writing the solution to a problem in a highly detailed manner that forces a computer to follow the directions to solve the problem. scientists have dubbed these code-based recipes algorithms3. Learning how to create algorithms involves first ldeterminging the problem and then converting the solution into an ordered steps that solve the problem. These ordered steps of instructions make use of the tools or building blocks of the programming language. 1.2 Programming in R All programming languages involves the same basic building blocks. This chapter introduced the building blocks in R. Once you master the building block in R, you can switch to other languages with little difficulties. Because our goal is to learn how to code to analyze data and produce graphics, we will begin learning R, which is well-suited to this purpose. First, we will learn how to work with basic programming concepts in R , then we will learn how to handle and analyse data in R. 1.2.1 What is R? R is primarily a programming language for statistical analysis data manipulation and graphics (R Core Team 2018). It is a powerful language used in mathematical operations, data-processing, analysis and graphical display of data. Xia, Sun, and Chen (2018) pointed out that R is a vehicle for newly developing methods of interactive data analysis. R have rapidly developed and extended its capability to a large collection of packages provided by researchers and volunteers. R can be downloaded from https://www.r-project.org and available for all thre major operating systems—Windows, Mac and Unix/Linux. Like other statistical software, R provides a statistical framework and terminal-based interface for users to parse commands for data ingestion, manipulation and graphics. The R programming usage has become one-stop solution to data analysis. R was created in 1993 and has evolved into a stable programming language. It has become a de facto standard for data analysis both in academic and industry sectors. R has its roots in the statistics community, being created by statistians for statistics. Many of its core tools are directed toward statistics. Being an open-source language, R has many advantage oover other commercial statistical platform like MATLAB, SAS and SPSS. The big rip for using R is its ecosystem of packages. R is an interpreted language—the expression specified in this languages executes line by line similar to other languages like python or ruby rather than compiling the source code an executable chunk as in C++. One of the power of R language is its dynamic—infers the data types of the variables based on the context. We do not need to declare variables separately. R is considered as esoteric because its syntax are easily understood by people from different fields. 1.2.2 Installing R R is available on most computing platform like Windows. Linux and Mac. There are two ways of installing R in the computer. The first is downloading latest version of R Binary and compiling R from the https://cran.r-project.org/ depending on your operating system. The compiled binary executes and install R in your machine. R can also be installed using packages managers. For example, Ubuntu users can install R using the apt-get package manager by running: &gt; sudo apt-get install r-base r-base-dev Similarly, Mac users can install R using ports &gt; sudo port install R There is an active community of R developers which regularly releases a new version R. Each version has a name assigned to it. Except for major resease, the version of R are usually backward compatible in terms of their funcitonality. The version and common packages used in this book can be accessed by simply passing a commands devtools::session_info() in the console. you can also check the version of R installed with version() function version _ platform x86_64-w64-mingw32 arch x86_64 os mingw32 system x86_64, mingw32 status major 3 minor 4.4 year 2018 month 03 day 15 svn rev 74408 language R version.string R version 3.4.4 (2018-03-15) nickname Someone to Lean On 1.2.3 What is RStudio? Once you have installed R on your computer, you might want to install another program called Rstudio. This program allows the user to run R in a more user-friendly environment (Xia, Sun, and Chen 2018). RStudio is a free and open-source integrated development environment (IDE) for R (RStudio Team 2016). You must have already installed R in your machine before you install Rstudio. You can download the software from the R-studio website at this link http:/www.rstudio.com. Rstudio work in the four operating systems—Windows, Mac, Ubuntu and Fedora. To obtain the reference infomation for citing RStudio in publication by simply typing RStudio.version() command in the console. 1.2.4 Basic Featurs of RStudio After the installation of Rstudio, the software is launched either by clicking the shortcult icon on the desktop or in startup menu of windows operating system. The sotware comes up with several window panels (Figure 1.1. The four windows in Rstudio are editor, console, worksapce and plots.` source editor and data viewer: The top left corner contains the script editor. This a simple text editor for writing and editing R scripts and markdown documents. Several tabs can be opened in the editor window at once, with each tab representing a different document. These files can be saved from the editor into the working directory. The editor window is also used to view data frame similar to Excel spreadsheet. Source editor is recommended in most programming work because of its efficient way to manage scripts and Rmarkdown document for reproducible work. environment (workspace) and history: The top right panel contains several tabs but I introduce the workspace and history tabs. The workspace list all the objects that are currently loaded in R’s memory. You can check each object by clicking them or run View() function in console. The history tab provides a record of the recent commands executed in the console, scripts or rmarkdown documents. R consoles: The bottom left window is the command line widely known as console. this window is similar to console in base R. This is used to directly enter commands into R. Once you have entered commands here, press enter to execute the command. The console is useful for entering single lines of code and running them. Oftentime this occurs when you are exploring or testing a certain task with a combinations of functions and objects. But because coding is all about creating scripts that automate the analytical process, you will find that very rare you use the the console. files, plots, packages, help, and viewer: The bottom-right window has five tabs for files, plots, package, help and viewer. The files tab allows browsing of the computers file directory. The plots tab will show recent plots and figures drawn with graphic functions in R. The packages tabl list all packages installed in R and provide tools for download new package and update packages. The help tab is an invaluable tab, it help to search for functions and see examples of how they are used. The viewer tab is like the plot tab that both are used to show recent plots and figures. However, while the plots is for static plot, the viewer is for animations and interactive plots and figures. Figure 1.1: The graphical user interface of RStudio An important concept in R is the current working directory. This is the file folder that R points to by default. By default the software stores all of your R-related files in the startup folder, which is the Document folder. Alternatively, you can create a personal working directory in which to store your R-related files with the setwd() function. This is especially important when reading in data to R. The current working directory should be set to the folder containing the data to be loaded into R. 1.2.5 Rstudio editor You should be making use of Rstudio’s text edditor to code in R. It is important to practice writing good code that are easy to read and understand what they mean. In short make sure your code is easy to read and understand what it does. This will help you understand your own code later, and help other people understand your code when shared or when they ask you for a help. 1.2.6 Rmarkdown Rstudio’s text editor allows to create markdown files called rmarkdown. Markdown is a plain text that combine codes and text and ability to ouput different format like word, PDF and HTML format. This ability of combining text and code has made rmarkdown a powerful markup language in R. In general, with rmarkdown you can write document with titles, headings, paragraphs, insert figures, tables and equations. Another useful feature of rmarkdown document is the option to publish R projects in various file format such as HTML, Latex, PDF EPUB, Word and many others. This feature enables you to share your results with colleagues who may or may not have R software. The published document includes formated plain text in section, heading and paragraphs that comes with code chunk, figures and tables. 1.2.7 Use descriptive names While programming, you will often declare and assign names of the variables. R usually will not care what name you give to any variables. But declare a descriptive name is informative because you easily remember what it contains. Therefore, its is encouraged to give names that represent the meaning of the data stored in each variable. 1.2.8 Use comments While working with R script, the hash tag # set a comment and tell the script to skip the line with the hash tag. In rmarkdown, the hash tag are used to set headings and therefore you can specify the comment with hash tage in the chunk code. Comments are useful as they help you and other people about a particular code and what particular aspect it does. Therefore, it is always recommend to write clear and precise comments that can help you in the future when you want to understand what the code does and also can help others follows with little consultation if shared. References "],
["getting-started.html", "Chapter 2 Getting started 2.1 Maths in R 2.2 Assignment operator 2.3 Setting Working Directory 2.4 Packages or Libraries 2.5 Understanding Data in R 2.6 Data Frame 2.7 Exercise 2.8 Exercise", " Chapter 2 Getting started This chapter provides example of foundational programming concepts in R. These include the basic tasks like importing data in R, manipulating data, visualizing the data and conduct explatory and inferencial statistics. These basics will provide building blocks for handling data, analysing data and make plots with R. In the examples, R codes are presented in the light gray chunk blocks. Inside these chunk blocks, lines that begin with two number signs (##) are the outputs of the preceding lines of codes that have been executed and lines without the number signs are are the code that generated the output. 2.1 Maths in R 2.1.1 Arithmetric R provides standard arithmetic operators for addition (+) , substraction (-), multiplication (*), division (/), and exponential (^). Because of the convinient, we will use Rstudio. In console just write an expression 2 + 3 and click enter. 2+3 ## [1] 5 As we expected, R returns the answer as 5. Unlike other programming languages, coding in R does not need to terminate the expression or lines with a semicolon. 10-4 ## [1] 6 23*2 ## [1] 46 8/2 ## [1] 4 5^2 ## [1] 25 5%%3 ## [1] 2 5%%5 ## [1] 0 2.1.2 Precedence R can be used to express complicated mathematical formulars. For anyone unfamiliar with writing formulas on computers, it is important to recognize that R will make assumptions abot which part of the formular to compute first. This is called predecence4. This i similar to a traditional and common mathematical term BODMAS. What is the answer for the mathematical expression in the chunk below. The answer should be 14. Accordings to BODMAS, the first operation in the expression is divide 8/2 = 4, then multiply 4*3 = 12, then addition 12+5 = 17 and last operation is substract 17-3 = 14 to obtain 14. 5-3+8/2*3 ## [1] 14 2.2 Assignment operator We often use an assignment operator to assing the value of an expression to a variable. R has two assignment operators—the conventional assignment operator =, which is present in most programming languages, and the arrows &lt;- and -&gt; which are specific to R. The expression x = 5 assign the value 5 to x, likewise the expression x &lt;- 5 and 5 -&gt; x have the same effect. Throughout this book, we stick on the conventional assignment operator (=) 2.2.1 Variables We can create expression using variables. for instance, we assign the value 5 to the variable x and evaluate the square of x using the exponential ^ operator. x = 5 x^2 ## [1] 25 R has many types of variables that store different kinds of data in different ways. Example you can store a list of numbers or text days= c(&quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;) speed = c(128, 158, 89) R has peculiar syntax when it comes to variable names. The dot character . has a completely different meaning as compared to other programming languages. In R, we can use . in the variable names, so x.1 and x_1 are perfectly valid. In practice, the dot operator is used as a visual separator in variable names, similar to underscore in most other programming languages. 2.2.2 Functions Functions in R are first class objects, which means that they can be treated much like any other R object. Importantly, Functions can be passed as arguments to other functions Functions can be nested, so that you can define a function inside of another function The return value of a function is the last expression in the function body to be evaluated. R functions arguments can be matched positionally or by name. So the following calls to sd are all equivalent data = rnorm(25) sum(data) ## [1] 1.597168 sd(data) ## [1] 1.318578 mean(data) ## [1] 0.06388672 median(data) ## [1] 0.2373929 2.2.3 Essential functions R has many built-in functions that can be used fo a great variety of tasks. These can be suplemented with packages, which contains more functions bundled in one document. Here is a list of common and widely used functions + rep() — repeates a value some number of times to make a list + seq() — creates a sequence of values between a start and end number and spaced at certain interval + aggregate() — used to bin data by condition + table() — used to summarise categorical data + plot() — graphical plots of data + hist() — a function for plotting a histogram + boxplot() — a function for plotting boxplot + mean() — compute arithmetric mean + sd() — compute arithmetric standard deviation + sum() — compute the total of the set of elements + length() — function to count the number of elements in a vector 2.3 Setting Working Directory Xia, Sun, and Chen (2018) defined a working directory as a folder in your computer or server where you stores the raw data, codes and output for that specific project. This folder is important in programming because it allows to read the data and write outputs to this working directory. In R you can set working directory with setwd() function and check whether you are in the right working directory with the getwd() function. getwd() setwd(&quot;./Data Manipulation/R_dege/&quot;) 2.4 Packages or Libraries R is made up of many user-written package. The base version of R allows user to get started in R, but the capabilities of base R are limited and additional packages are required for smooth performance of working with data. packages are collections of R functions, data, and compiled code in a well-defined format. A package bundles together code, data, documentation and tests and provide ana easy method to share with others. Until November 2018, there were 1300+ packages available for download on CRAN and countless more avaialble trought GitHub. The huge number of package has made R so successful and the chance is that some one has already created a package that can solve the problem you about to tackle and you can benefit from their work by downloading their package. 2.4.1 Installing packages R comes with a standard set of packages. Others are available for download and installation. The primary of stable package is the CRAN. In R you can install a package from CRAN with an install.packages(&quot;packagename&quot;) function that allows you to install the package you want to use into R. In have already installed the ggplot2 packages in my machine, so if you want to install in your machine you can simply uncomment the chunk below by removing the hash tag (#) ## install.packages(&quot;ggplot2&quot;) ## install.packages(&quot;dplyr&quot;) ## install.packages(&quot;lubridate&quot;) ## install.packages(&quot;factoextra&quot;) ## install.packages(&quot;readxl&quot;) ## install.packages(&quot;kableextra&quot;) ## install.packages(&quot;haven&quot;) ## install.packages(&quot;readr&quot;) 2.4.2 Loading packages Once package is downloaded and installed in your computer, you have to them into the session to access its functions and resources of the package. Yu can load the packages you want ot use with ether library() or required() function. require(dplyr) library(readr) require(lubridate) library(readxl) require(haven) library(ggplot2) require(kableExtra) 2.5 Understanding Data in R Clearing the workspace is always recommended before working on a new R project to avoid name conflicts with provious projects. We can also clear all figures using graphics.off()' function and clear the console with a combinantion ofCTRL+L`. It is a good code practise that a new R project start with the code in the chunk below: rm(list = ls()) graphics.off() 2.5.1 Data Types R is a flexible language that allows to work with different kind of data format (Boehmke 2016). This inluced integer, numeric, character, complex, dates and logical. The default data type or class in R is double precision—numeric. In a nutshell, R treats all kind of data into five categories but we deal with only four in this book. Before proceeding, we need to clear the workspace by typing rm(list = ls()) after the prompt in the in a console. Integers:Integer values do not have decimal places. They are commonly used for counting or indexing. aa = c(20,68,78,50) You can check if the data is integer with is.integer() and can convert numeric value to an integer with as.integer() is.integer(aa) ## [1] FALSE You can query the class of the object with the class() to know the class of the object class(aa) ## [1] &quot;numeric&quot; Although the object bb is integer as confirmed with as.integer() function, the class() ouput the answer as numeric. This is because the defaul type of number in r is numeric. However, you can use the function as.integer() to convert numeric value to integer class(as.integer(aa)) ## [1] &quot;integer&quot; Numeric: The numeric class holds the set of real numbers — decimal place numbers. The numeric class is more general than the integer class, and inclused the integer numbers. These could be any number (whole or decimal number). You can check if the data is integer with is.integer() bb = c(12.5, 45.68, 2.65) class(bb) ## [1] &quot;numeric&quot; is.numeric(bb) ## [1] TRUE Strings: These collection of characters. This often are text data like names. You can check if the data is integer with is.character() kata = c(&quot;Dege&quot;, &quot;Mchikichini&quot;, &quot;Mwembe Mdogo&quot;, &quot;Cheka&quot;) class(kata) ## [1] &quot;character&quot; Factor: These are strings from finite set of values. For example, we might wish to store a variable that records gender of people. You can check if the data is factor with is.factor() and use as.factor() to convert string to factor sex = c(&quot;Male&quot;, &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;) sex = as.factor(sex) class(sex) ## [1] &quot;factor&quot; levels(sex) ## [1] &quot;Female&quot; &quot;Male&quot; Often times we need to know the possible groups that are in the factor data. This can be achieved with the levels() function levels(sex) ## [1] &quot;Female&quot; &quot;Male&quot; levels(kata) ## NULL Often we wish to take a continuous numerical vector and transform it into a factor. The function cut() takes a vector of numerical data and creates a factor based on your give cut-points. Let us make a fictional income of 508 people with rnorm() function. income = rnorm(n = 508, mean = 500, sd = 80) hist(income, col = &quot;green&quot;, main = &quot;&quot;, las = 1, xlab = &quot;Individual Income&quot;) Figure 2.1: Income distribution #mosaic::plotDist(dist = &quot;norm&quot;, mean = 500, sd = 80) We can now breaks the distribution into groups and make a simple plot as shown in figure 2.2, where those with income less than 400 were about 50, followed with a group with income range between 400 and 500 of about 200 and 250 people receive income above 500 group = cut(income, breaks = c(300,400,500,800), labels = c(&quot;Below 400&quot;, &quot;400-500&quot;, &quot;Above 500&quot;)) is.factor(group) ## [1] TRUE levels(group) ## [1] &quot;Below 400&quot; &quot;400-500&quot; &quot;Above 500&quot; barplot(table(group), las = 1, horiz = FALSE, col = c(&quot;blue&quot;, &quot;red&quot;, &quot;blue&quot;), ylab = &quot;Frequency&quot;, xlab = &quot;Group of Income&quot;) Figure 2.2: Barplot of grouped income data = data.frame(group, income) Logicals: This is a special case of a factor that can only take on the values TRUE and FALSE. R is case-sensitive, therefore you must always capitalize TRUE and FALSE in function in R. Date and time 2.5.2 Vectors Ofen times we want to store a set of numbers in once place. One way to do this is using the vectors in R. Vectors store severl numbers– a set of numbers in one container. let us look on the example below id = c(1,2,3,4,5) people = c(158,659,782,659,759) street = c(&quot;Dege&quot;, &quot;Mchikichini&quot;, &quot;Mwembe Mdogo&quot;, &quot;Mwongozo&quot;, &quot;Cheka&quot;) Notice that the c() function, which is short for concatenate wraps the list of numbers. The c() function combines all numbers together into one container. Notice also that all the individual numbers are separated with a comma. The comma is reffered to an an item-delimiter. It allows R to hold each of the numbers separately. This is vital as without the item-delimiter, R will treat a vector as one big, unsperated number. 2.5.3 Indexing the element One advantage of vector is that you can extract individual element in the vector object by indexing, which is accomplished using the square bracket as illustrated below. id[5] ## [1] 5 people[5] ## [1] 759 street[5] ## [1] &quot;Cheka&quot; Apart from extracting single element, indexing allows to extract a range of element in a vector. This is extremely important because it allows to subset a portion of data in a vector. A colon operator is used to extract a range of data street[2:4] ## [1] &quot;Mchikichini&quot; &quot;Mwembe Mdogo&quot; &quot;Mwongozo&quot; 2.5.4 Adding and Replacing an element in a vector It is possible to add element of an axisting vecor. Here ia an example id[6] = 6 people[6] = 578 street[6] = &quot;Mwongozo&quot; Sometimes you may need to replace an element from a vector, this can be achieved with indexing people[1] = 750 2.5.5 Number of elements in a vector Sometimes you may have a long vector and want to know the numbers of elements in the object. R has length() function that allows you to query the vector and print the answer length(people) ## [1] 6 2.6 Data Frame data.frame is very much like a simple Excel spreadsheet where each column represents a variable type and each row represent observations. Perhaps the easiest way to create a data frame is to parse vectors in data.frame() function. # create vectors Name = c(&#39;Bob&#39;,&#39;Jeff&#39;,&#39;Mary&#39;) Score = c(90, 75, 92) dt = data.frame(Name, Score) Table 2.1 show the the data frame created by fusing the two vectors together. Table 2.1: Variables in the data frame Name Score Bob 90 Jeff 75 Mary 92 Because the columns have meaning and we have given them column names, it is desirable to want to access an element by the name of the column as opposed to the column number.In large Excel spreadsheets I often get annoyed trying to remember which column something was. The $sign and []are used in R to select variable from the data frame. dt$Name ## [1] Bob Jeff Mary ## Levels: Bob Jeff Mary dt[,1] ## [1] Bob Jeff Mary ## Levels: Bob Jeff Mary dt$Score ## [1] 90 75 92 dt[,2] ## [1] 90 75 92 R has build in dataset that we can use for illustration. For example, Longley (1967) created a longley dataset, which is data frame with 7 economic variables observed every year from 1947 ti 1962 (Table 2.2). We can add the data in the workspace with data() function data(longley) longley %&gt;% kable(caption = &quot;Longleys&#39; Economic dataset&quot;, align = &quot;c&quot;, row.names = F) %&gt;% column_spec(1:7, width = &quot;3cm&quot;) Table 2.2: Longleys’ Economic dataset GNP.deflator GNP Unemployed Armed.Forces Population Year Employed 83.0 234.289 235.6 159.0 107.608 1947 60.323 88.5 259.426 232.5 145.6 108.632 1948 61.122 88.2 258.054 368.2 161.6 109.773 1949 60.171 89.5 284.599 335.1 165.0 110.929 1950 61.187 96.2 328.975 209.9 309.9 112.075 1951 63.221 98.1 346.999 193.2 359.4 113.270 1952 63.639 99.0 365.385 187.0 354.7 115.094 1953 64.989 100.0 363.112 357.8 335.0 116.219 1954 63.761 101.2 397.469 290.4 304.8 117.388 1955 66.019 104.6 419.180 282.2 285.7 118.734 1956 67.857 108.4 442.769 293.6 279.8 120.445 1957 68.169 110.8 444.546 468.1 263.7 121.950 1958 66.513 112.6 482.704 381.3 255.2 123.366 1959 68.655 114.2 502.601 393.1 251.4 125.368 1960 69.564 115.7 518.173 480.6 257.2 127.852 1961 69.331 116.9 554.894 400.7 282.7 130.081 1962 70.551 Sometimes you may need to create set of values and store them in vectors, then combine the vectors into a data frame. Let us see how this can be done. First create three vectors. One contains id for ten individuals, the second vector hold the time each individual signed in the attendane book and the third vector is the distance of each individual from office. We can concatenate the set of values to make vectors. id = c(1,2,3,4,5,6,7,8,9,10) time = ymd_hms(c(&quot;2018-11-20 06:35:25 EAT&quot;, &quot;2018-11-20 06:52:05 EAT&quot;, &quot;2018-11-20 07:08:45 EAT&quot;, &quot;2018-11-20 07:25:25 EAT&quot;, &quot;2018-11-20 07:42:05 EAT&quot;, &quot;2018-11-20 07:58:45 EAT&quot;, &quot;2018-11-20 08:15:25 EAT&quot;, &quot;2018-11-20 08:32:05 EAT&quot;, &quot;2018-11-20 08:48:45 EAT&quot;, &quot;2018-11-20 09:05:25 EAT&quot;), tz = &quot;&quot;) distance = c(20, 85, 45, 69, 42, 52, 6, 45, 36, 7) Once we have the vectors that have the same length dimension, we can use the function data.frame() to combine the the three vectors into one data frame shown in table 2.3 arrival = data.frame(id, time, distance) Table 2.3: The time employees enter into the office with the distance from their residential areas to the office IDs Time Distance 1 2018-11-20 06:35:25 20 2 2018-11-20 06:52:05 85 3 2018-11-20 07:08:45 45 4 2018-11-20 07:25:25 69 5 2018-11-20 07:42:05 42 6 2018-11-20 07:58:45 52 7 2018-11-20 08:15:25 6 8 2018-11-20 08:32:05 45 9 2018-11-20 08:48:45 36 10 2018-11-20 09:05:25 7 2.7 Exercise Create a vector of character strings with six elements test &lt;- c(&#39;red&#39;,&#39;red&#39;,&#39;blue&#39;,&#39;yellow&#39;,&#39;blue&#39;,&#39;green&#39;) and then Transform the test vector just you created into a factor. Use the levels() command to determine the levels (and order) of the factor you just created. Transform the factor you just created into integers. Comment on the relationship between the integers and the order of the levels you found in part (b). Use some sort of comparison to create a vector that identifies which factor elements are the red group. Suppose we vectors that give a students name, their GPA, and their major. We want to come up with a list of forestry students with a GPA of greater than 3.0. Name &lt;- c(&#39;Adam&#39;,&#39;Benjamin&#39;,&#39;Caleb&#39;,&#39;Daniel&#39;,&#39;Ephriam&#39;, &#39;Frank&#39;,&#39;Gideon&#39;) GPA &lt;- c(3.2, 3.8, 2.6, 2.3, 3.4, 3.7, 4.0) Major &lt;- c(&#39;Math&#39;,&#39;Forestry&#39;,&#39;Biology&#39;,&#39;Forestry&#39;,&#39;Forestry&#39;,&#39;Math&#39;,&#39;Forestry&#39;) Create a vector of TRUE/FALSE values that indicate whether the students GPA is greater than 3.0. Create a vector of TRUE/FALSE values that indicate whether the students’ major is forestry. Create a vector of TRUE/FALSE values that indicates if a student has a GPA greater than 3.0 and is a forestry major. Convert the vector of TRUE/FALSE values in part (c) to integer values using the as.numeric() function. Which numeric value corresponds to TRUE? Sum (using the sum() function) the vector you created to count the number of students with GPA &gt; 3.0 and are a forestry major. 2.8 Exercise Create a data.frame named my.trees that has the following columns: Girth = c(8.3, 8.6, 8.8, 10.5, 10.7, 10.8, 11.0) Height= c(70, 65, 63, 72, 81, 83, 66) Volume= c(10.3, 10.3, 10.2, 16.4, 18.8, 19.7, 15.6) Extract the third observation (i.e. the third row) Extract the Girth column referring to it by name (don’t use whatever order you placed the columns in). Print out a data frame of all the observations except for the fourth observation. (i.e. Remove the fourth observation/row.) References "],
["readr.html", "Chapter 3 Importing data with readr 3.1 Comma-Separated (.csv) 3.2 Microsoft Excel(.xlsx) 3.3 Writing t a File 3.4 Basic Data Manipulation", " Chapter 3 Importing data with readr You can lean R with the dataset it comes with when you install it in your machine. But sometimes you want to use the real data you or someone gathered already. One of critical steps for data processing is to import data with special format into R workspace.Data import refers to read data from the working directory into the workspace (Matthew 2018). In this chapter you will learn how to import common files into R. We will only focus on two common types of tabular data storage format—The comma-seprated .csv and excell spreadsheet (.xlsx). In later chapter we will explain how to read other types of data into R. 3.1 Comma-Separated (.csv) The most commonly format that R like is the comma-separated files. Although Base R provides various functions like read.table(), read.csv(), read.table() and read.csv2() to import data from the local directories into R workspace, for this book we use an read_csv() function from readr. Before we import the data, we need to load the packages that we will use their functions in this chapeter require(dplyr) require(readr) require(lubridate) require(readxl) require(haven) require(ggplot2) require(kableExtra) Consider a tabular data stored in my working directory in the .csv format in figure 3.1. Figure 3.1: A screenshot of the sample dataset We can import it with the read_csv() functions as: demographic = read_csv(&quot;demographic.csv&quot;) Parsed with column specification: cols( name = col_character(), continent = col_character(), area = col_double(), pop = col_double(), lifeExp = col_double(), gdpPercap = col_double() ) When read_csv() has imported the data into R workspace, it prints out the name and type of of data for each variable. By simply glimpse the dataset, we see the format of the data is as expected. It has six variables(columns) and 177 observations (rows) similar to figure 3.1. Table 3.1 show sample of imported dataset. It contains six variables are name of the country, continent, areas of the country in square kilometer, population of the country, life expectancy and the GDP of the country in percent. The NA values indicates missing data in the data set. Table 3.1: World demographic information Country Continent Area (Km^2) Population Life Epectancy (Years) GDP Mauritania Africa 1054107.19 4063920 62.91 3655.39 Bangladesh Asia 133782.14 159405279 71.80 2973.04 Uzbekistan Asia 461410.26 30757700 71.04 5370.87 Malawi Africa 111197.02 17068838 61.93 1090.37 Vietnam Asia 335990.80 92544915 75.86 5264.83 Brazil South America 8508557.09 204213133 75.04 15374.26 Burundi Africa 26238.95 9891790 56.69 803.17 Paraguay South America 401335.92 6552584 72.91 8501.54 Trinidad and Tobago North America 7737.81 1354493 70.43 31181.82 Timor-Leste Asia 14714.93 1212814 68.28 6262.91 Palestine Asia 5037.10 4294682 73.13 4319.53 Vanuatu Oceania 7490.04 258850 71.71 2892.34 3.2 Microsoft Excel(.xlsx) Commonly our data is stored as a MS Excel file. we can import the file with read_xlsx() function of readxl package. The readxl package provides a function read_exel() that allows us to specify which sheet within the Excel file to read and what character specifies missing data (it assumes a blank cell is missing data if you don’t specifying anything). The function automatically convert the worksheet into a .csv file and read it. audit = readxl::read_xlsx(&quot;audit.xlsx&quot;) The audit file is from the rattle package developed by Maindonald (2012). The dataset which is artificially constructed that has some of the charactersitcis of a true financial audit. I just saved it into the working directory as Excel spreadsheet. We will use this file to illustrate how to import the excel file into R workspace with readxl package (Wickham and Bryan 2018). We look on the internal structure of the audit file with the glimpse() function. You can interact with the table that show all variables and observations (Table 3.1) audit%&gt;%glimpse() ## Observations: 2,000 ## Variables: 13 ## $ ID &lt;dbl&gt; 1004641, 1010229, 1024587, 1038288, 1044221, 1... ## $ Age &lt;dbl&gt; 38, 35, 32, 45, 60, 74, 43, 35, 25, 22, 48, 60... ## $ Employment &lt;chr&gt; &quot;Private&quot;, &quot;Private&quot;, &quot;Private&quot;, &quot;Private&quot;, &quot;P... ## $ Education &lt;chr&gt; &quot;College&quot;, &quot;Associate&quot;, &quot;HSgrad&quot;, &quot;Bachelor&quot;, ... ## $ Marital &lt;chr&gt; &quot;Unmarried&quot;, &quot;Absent&quot;, &quot;Divorced&quot;, &quot;Married&quot;, ... ## $ Occupation &lt;chr&gt; &quot;Service&quot;, &quot;Transport&quot;, &quot;Clerical&quot;, &quot;Repair&quot;, ... ## $ Income &lt;dbl&gt; 81838.00, 72099.00, 154676.74, 27743.82, 7568.... ## $ Gender &lt;chr&gt; &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Mal... ## $ Deductions &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... ## $ Hours &lt;dbl&gt; 72, 30, 40, 55, 40, 30, 50, 40, 40, 37, 35, 40... ## $ IGNORE_Accounts &lt;chr&gt; &quot;UnitedStates&quot;, &quot;Jamaica&quot;, &quot;UnitedStates&quot;, &quot;Un... ## $ RISK_Adjustment &lt;dbl&gt; 0, 0, 0, 7298, 15024, 0, 22418, 0, 0, 0, 0, 0,... ## $ TARGET_Adjusted &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0... DT::datatable(audit, rownames = FALSE, caption = &quot;An Interactive table showing the audit data&quot;) Look the frequency audit$Employment%&gt;%table() ## . ## Consultant NA Private PSFederal PSLocal PSState ## 148 100 1411 69 119 72 ## SelfEmp Unemployed Volunteer ## 79 1 1 audit$Gender%&gt;%table()%&gt;%barplot(horiz = TRUE) as.POSIXct(&quot;1920-10-12 10:05:3&quot;) %&gt;% class() ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; audit$Marital%&gt;%table()%&gt;%barplot(horiz = TRUE) 3.3 Writing t a File Sometimes you work in the document and you want to export to a file. readr has write_csv() and write_tsv() functions that allows to export data frames from workspace to working directory write_csv(audit, &quot;audit.csv&quot;) write_ Hadley and Grolemund (2016) recomment the use of write_excel_csv() function when you want to export a data frame to Excel. readr has other tools that export files to other software like SAS, SPSS and more … write_excel_csv(audit, &quot;audit.xls&quot;) 3.4 Basic Data Manipulation In this section, we brifely introduce some basic data handling and manipulation techniques, which are mostly associated with data frame. A data frame is a a tabular shaped contains columns and rows of equal length. In general a data frame structure with rows representing observations or measurements and with columns containing variables. 3.4.1 Explore the Data Frame We can visualize the table by simply run the name of the data flights flights = read_csv(&quot;flights.csv&quot;) ## Warning: Missing column names filled in: &#39;X1&#39; [1] ## Parsed with column specification: ## cols( ## .default = col_integer(), ## carrier = col_character(), ## tailnum = col_character(), ## origin = col_character(), ## dest = col_character(), ## time_hour = col_character() ## ) ## See spec(...) for full column specifications. flights ## # A tibble: 336,776 x 20 ## X1 year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2013 1 1 517 515 2 830 ## 2 2 2013 1 1 533 529 4 850 ## 3 3 2013 1 1 542 540 2 923 ## 4 4 2013 1 1 544 545 -1 1004 ## 5 5 2013 1 1 554 600 -6 812 ## 6 6 2013 1 1 554 558 -4 740 ## 7 7 2013 1 1 555 600 -5 913 ## 8 8 2013 1 1 557 600 -3 709 ## 9 9 2013 1 1 557 600 -3 838 ## 10 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;int&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;int&gt;, distance &lt;int&gt;, hour &lt;int&gt;, ## # minute &lt;int&gt;, time_hour &lt;chr&gt; we can use class() to check if the data is data frame flights %&gt;% class() ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; We can use names() to extract the variable names flights %&gt;% names() ## [1] &quot;X1&quot; &quot;year&quot; &quot;month&quot; &quot;day&quot; ## [5] &quot;dep_time&quot; &quot;sched_dep_time&quot; &quot;dep_delay&quot; &quot;arr_time&quot; ## [9] &quot;sched_arr_time&quot; &quot;arr_delay&quot; &quot;carrier&quot; &quot;flight&quot; ## [13] &quot;tailnum&quot; &quot;origin&quot; &quot;dest&quot; &quot;air_time&quot; ## [17] &quot;distance&quot; &quot;hour&quot; &quot;minute&quot; &quot;time_hour&quot; We can explore the internal structure of flights object with a dplyr()’s function glimpse() flights %&gt;% glimpse() ## Observations: 336,776 ## Variables: 20 ## $ X1 &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ... ## $ year &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013,... ## $ month &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,... ## $ day &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,... ## $ dep_time &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 55... ## $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 60... ## $ dep_delay &lt;int&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2... ## $ arr_time &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 7... ## $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 7... ## $ arr_delay &lt;int&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -... ## $ carrier &lt;chr&gt; &quot;UA&quot;, &quot;UA&quot;, &quot;AA&quot;, &quot;B6&quot;, &quot;DL&quot;, &quot;UA&quot;, &quot;B6&quot;, &quot;EV&quot;,... ## $ flight &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79... ## $ tailnum &lt;chr&gt; &quot;N14228&quot;, &quot;N24211&quot;, &quot;N619AA&quot;, &quot;N804JB&quot;, &quot;N668DN... ## $ origin &lt;chr&gt; &quot;EWR&quot;, &quot;LGA&quot;, &quot;JFK&quot;, &quot;JFK&quot;, &quot;LGA&quot;, &quot;EWR&quot;, &quot;EWR&quot;... ## $ dest &lt;chr&gt; &quot;IAH&quot;, &quot;IAH&quot;, &quot;MIA&quot;, &quot;BQN&quot;, &quot;ATL&quot;, &quot;ORD&quot;, &quot;FLL&quot;... ## $ air_time &lt;int&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138... ## $ distance &lt;int&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 94... ## $ hour &lt;int&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5,... ## $ minute &lt;int&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, ... ## $ time_hour &lt;chr&gt; &quot;1/1/2013 5:00&quot;, &quot;1/1/2013 5:00&quot;, &quot;1/1/2013 5:0... We can check how rows (observations/measurements) and columns (variables/fields) are in the data flights %&gt;% dim() ## [1] 336776 20 The number of rows (observation) can be obtained using nrow() function flights %&gt;% nrow() ## [1] 336776 The number of columns (variables) can be obtained using ncol() function flights %&gt;% ncol() ## [1] 20 The length of the data frame is given by flights %&gt;% length() ## [1] 20 3.4.2 simmple summary statistics The most helpful function for for summarizing rows and columns is summary(), which gives a collection of basim cummary statistics. The first method is to calculate some basic summary statistics (minimum, 25th, 50th, 75th percentiles, maximum and mean) of each column. If a column is categorical, the summary function will return the number of observations in each category. flights %&gt;% summary() ## X1 year month day ## Min. : 1 Min. :2013 Min. : 1.000 Min. : 1.00 ## 1st Qu.: 84195 1st Qu.:2013 1st Qu.: 4.000 1st Qu.: 8.00 ## Median :168389 Median :2013 Median : 7.000 Median :16.00 ## Mean :168389 Mean :2013 Mean : 6.549 Mean :15.71 ## 3rd Qu.:252582 3rd Qu.:2013 3rd Qu.:10.000 3rd Qu.:23.00 ## Max. :336776 Max. :2013 Max. :12.000 Max. :31.00 ## ## dep_time sched_dep_time dep_delay arr_time ## Min. : 1 Min. : 106 Min. : -43.00 Min. : 1 ## 1st Qu.: 907 1st Qu.: 906 1st Qu.: -5.00 1st Qu.:1104 ## Median :1401 Median :1359 Median : -2.00 Median :1535 ## Mean :1349 Mean :1344 Mean : 12.64 Mean :1502 ## 3rd Qu.:1744 3rd Qu.:1729 3rd Qu.: 11.00 3rd Qu.:1940 ## Max. :2400 Max. :2359 Max. :1301.00 Max. :2400 ## NA&#39;s :8255 NA&#39;s :8255 NA&#39;s :8713 ## sched_arr_time arr_delay carrier flight ## Min. : 1 Min. : -86.000 Length:336776 Min. : 1 ## 1st Qu.:1124 1st Qu.: -17.000 Class :character 1st Qu.: 553 ## Median :1556 Median : -5.000 Mode :character Median :1496 ## Mean :1536 Mean : 6.895 Mean :1972 ## 3rd Qu.:1945 3rd Qu.: 14.000 3rd Qu.:3465 ## Max. :2359 Max. :1272.000 Max. :8500 ## NA&#39;s :9430 ## tailnum origin dest air_time ## Length:336776 Length:336776 Length:336776 Min. : 20.0 ## Class :character Class :character Class :character 1st Qu.: 82.0 ## Mode :character Mode :character Mode :character Median :129.0 ## Mean :150.7 ## 3rd Qu.:192.0 ## Max. :695.0 ## NA&#39;s :9430 ## distance hour minute time_hour ## Min. : 17 Min. : 1.00 Min. : 0.00 Length:336776 ## 1st Qu.: 502 1st Qu.: 9.00 1st Qu.: 8.00 Class :character ## Median : 872 Median :13.00 Median :29.00 Mode :character ## Mean :1040 Mean :13.18 Mean :26.23 ## 3rd Qu.:1389 3rd Qu.:17.00 3rd Qu.:44.00 ## Max. :4983 Max. :23.00 Max. :59.00 ## You noticed that the summary() function provide the common metric for central tendency and measure of dispersion. We will look at them later. Now we turn to our favourite package dplyr References "],
["dplyr.html", "Chapter 4 Manipulating Data with dplyr 4.1 Why use dplyr? 4.2 dplyr functionality 4.3 filter: Keep rows matching criteria 4.4 select: Pick columns by name 4.5 “Chaining” or “Pipelining” 4.6 Pipping with", " Chapter 4 Manipulating Data with dplyr Although many fundamental data processing functions exist in R, they have been a bit convoluted to date and have lacked consistent coding and the ability to easily flow together. This leads to difficult-to-read nested functions and/or choppy code. R Studio is driving a lot of new packages to collate data management tasks and better integrate them with other analysis activities. As a result, a lot of data processing tasks are becoming packaged in more cohesive and consistent ways, which leads to: More efficient code Easier to remember syntax Easier to read syntax The dplyr package provides a set of functions for efficiently manipulating datasets in R writen by Wickham et al. (2018). The package make it easy to transform and summarise tabular data with rows and columns. The dplyr packages contains set of functions—verbs that perfom most common data manipulation tasks like When working with data you must: Figure out what you want to do. Describe those tasks in the form of a computer program. Execute the program. The dplyr package makes these steps fast and easy: By constraining your options, it helps you think about your data manipulation challenges. It provides simple “verbs”, functions that correspond to the most common data manipulation tasks, to help you translate your thoughts into code. It uses efficient backends, so you spend less time waiting for the computer. 4.1 Why use dplyr? Great for data exploration and manipulation Intuitive to write and easy to read, especially when using the chaining syntax Fast on data frame—tabular dataset 4.2 dplyr functionality Five basic verbs: select() to select columns based on their names filter() to rows in data frame arrange() to re-order or arrange the rows in ascending or descending order mutate() to create new columns—add new variable summarise() to make a summary of variable(s) group_by() to group observation sample_n() and rename()to make random sample from the data set The group_by() function perform other common task which are related to the split-apply-combine concept. The dplyr package comes with the pipe operateor %&gt;% from the magrittr package. The pipe operator is very useful for combining several functions in a chain. 4.3 filter: Keep rows matching criteria Base R approach to filtering forces you to repeat the data frame’s name dplyr approach is simpler to write and read Command structure (for all dplyr verbs): first argument is a data frame return value is a data frame nothing is modified in place Note: dplyr generally does not preserve row names require(dplyr) require(readr) require(lubridate) require(readxl) require(haven) require(ggplot2) require(kableExtra) flights = read_csv(&quot;flights.csv&quot;) %&gt;% select(-X1) ## Warning: Missing column names filled in: &#39;X1&#39; [1] ## Parsed with column specification: ## cols( ## .default = col_integer(), ## carrier = col_character(), ## tailnum = col_character(), ## origin = col_character(), ## dest = col_character(), ## time_hour = col_character() ## ) ## See spec(...) for full column specifications. # base R approach to view all flights on January 1 flights[flights$month==1 &amp; flights$day==1, ] # dplyr approach # note: you can use comma or ampersand to represent AND condition filter(flights, month==1, day==1) ## # A tibble: 842 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 832 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;int&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;int&gt;, distance &lt;int&gt;, hour &lt;int&gt;, ## # minute &lt;int&gt;, time_hour &lt;chr&gt; # use pipe for OR condition 4.4 select: Pick columns by name Base R approach is awkward to type and to read dplyr approach uses similar syntax to filter Like a SELECT in SQL # base R approach to select DepTime, and ArrTime flights[, c(&quot;dep_time&quot;, &quot;arr_time&quot;)] # dplyr approach select(flights, dep_time, arr_time) ## # A tibble: 336,776 x 2 ## dep_time arr_time ## &lt;int&gt; &lt;int&gt; ## 1 517 830 ## 2 533 850 ## 3 542 923 ## 4 544 1004 ## 5 554 812 ## 6 554 740 ## 7 555 913 ## 8 557 709 ## 9 557 838 ## 10 558 753 ## # ... with 336,766 more rows # use colon to select multiple contiguous columns, and use `contains` to match columns by name # note: `starts_with`, `ends_with`, and `matches` (for regular expressions) can also be used to match columns by name select(flights, year:day, contains(&quot;taxi&quot;), contains(&quot;delay&quot;)) ## # A tibble: 336,776 x 5 ## year month day dep_delay arr_delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 2 11 ## 2 2013 1 1 4 20 ## 3 2013 1 1 2 33 ## 4 2013 1 1 -1 -18 ## 5 2013 1 1 -6 -25 ## 6 2013 1 1 -4 12 ## 7 2013 1 1 -5 19 ## 8 2013 1 1 -3 -14 ## 9 2013 1 1 -3 -8 ## 10 2013 1 1 -2 8 ## # ... with 336,766 more rows 4.5 “Chaining” or “Pipelining” Bache and Wickham (2014) developed a magrittr package, which has changed the way coding is done in R. It introduce the pipe operator %&gt;% widely known as THEN. Usual way to perform multiple operations in R was through nesting. However, magrittr package introduced a natural order by using the %&gt;% chain multiple operations # nesting method to select UniqueCarrier and DepDelay columns and filter for delays over 60 minutes filter(select(flights, carrier, dep_delay), dep_delay &gt; 60) # chaining method flights %&gt;% select(carrier, dep_delay) %&gt;% filter(dep_delay &gt; 60) ## # A tibble: 26,581 x 2 ## carrier dep_delay ## &lt;chr&gt; &lt;int&gt; ## 1 MQ 101 ## 2 AA 71 ## 3 MQ 853 ## 4 UA 144 ## 5 UA 134 ## 6 EV 96 ## 7 MQ 71 ## 8 B6 77 ## 9 EV 70 ## 10 EV 115 ## # ... with 26,571 more rows Chaining increases readability significantly when there are many commands Operator is automatically imported from the magrittr package Can be used to replace nesting in R commands outside of dplyr. For example, we can create two vectors and calculate Euclidian distance between them using the mathematical equation (4.1) \\[ \\begin{equation} \\theta\\: = \\: \\sqrt {\\sum (x_1 - x_2)^2} \\tag{4.1} \\end{equation} \\] x1 &lt;- 1:5; x2 &lt;- 2:6 sqrt(sum((x1-x2)^2)) # chaining method (x1-x2)^2 %&gt;% sum() %&gt;% sqrt() ## [1] 2.236068 4.6 Pipping with 4.6.1 Choosing columns: select(), rename() Often you work with large datasets with many columns but only a few are actually of interest to you. select() allows you to rapidly zoom in on a useful subset using operations that usually only work on numeric variable positions: # besides just using select() to pick columns... flights %&gt;% select(carrier, flight) ## # A tibble: 336,776 x 2 ## carrier flight ## &lt;chr&gt; &lt;int&gt; ## 1 UA 1545 ## 2 UA 1714 ## 3 AA 1141 ## 4 B6 725 ## 5 DL 461 ## 6 UA 1696 ## 7 B6 507 ## 8 EV 5708 ## 9 B6 79 ## 10 AA 301 ## # ... with 336,766 more rows # ...you can use the minus sign to hide columns flights %&gt;% select(-month, -day) ## # A tibble: 336,776 x 17 ## year dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 517 515 2 830 819 ## 2 2013 533 529 4 850 830 ## 3 2013 542 540 2 923 850 ## 4 2013 544 545 -1 1004 1022 ## 5 2013 554 600 -6 812 837 ## 6 2013 554 558 -4 740 728 ## 7 2013 555 600 -5 913 854 ## 8 2013 557 600 -3 709 723 ## 9 2013 557 600 -3 838 846 ## 10 2013 558 600 -2 753 745 ## # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;int&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;int&gt;, distance &lt;int&gt;, hour &lt;int&gt;, minute &lt;int&gt;, ## # time_hour &lt;chr&gt; # hide a range of columns flights %&gt;% select(-(dep_time:arr_delay)) # hide any column with a matching name flights %&gt;% select(-contains(&quot;time&quot;)) ## # A tibble: 336,776 x 13 ## year month day dep_delay arr_delay carrier flight tailnum origin ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2013 1 1 2 11 UA 1545 N14228 EWR ## 2 2013 1 1 4 20 UA 1714 N24211 LGA ## 3 2013 1 1 2 33 AA 1141 N619AA JFK ## 4 2013 1 1 -1 -18 B6 725 N804JB JFK ## 5 2013 1 1 -6 -25 DL 461 N668DN LGA ## 6 2013 1 1 -4 12 UA 1696 N39463 EWR ## 7 2013 1 1 -5 19 B6 507 N516JB EWR ## 8 2013 1 1 -3 -14 EV 5708 N829AS LGA ## 9 2013 1 1 -3 -8 B6 79 N593JB JFK ## 10 2013 1 1 -2 8 AA 301 N3ALAA LGA ## # ... with 336,766 more rows, and 4 more variables: dest &lt;chr&gt;, ## # distance &lt;int&gt;, hour &lt;int&gt;, minute &lt;int&gt; # pick columns using a character vector of column names cols &lt;- c(&quot;carrier&quot;, &quot;flight&quot;, &quot;tailnum&quot;) flights %&gt;% select(one_of(cols)) ## # A tibble: 336,776 x 3 ## carrier flight tailnum ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 UA 1545 N14228 ## 2 UA 1714 N24211 ## 3 AA 1141 N619AA ## 4 B6 725 N804JB ## 5 DL 461 N668DN ## 6 UA 1696 N39463 ## 7 B6 507 N516JB ## 8 EV 5708 N829AS ## 9 B6 79 N593JB ## 10 AA 301 N3ALAA ## # ... with 336,766 more rows # select() can be used to rename columns, though all columns not mentioned are dropped flights %&gt;% select(tail = tailnum) ## # A tibble: 336,776 x 1 ## tail ## &lt;chr&gt; ## 1 N14228 ## 2 N24211 ## 3 N619AA ## 4 N804JB ## 5 N668DN ## 6 N39463 ## 7 N516JB ## 8 N829AS ## 9 N593JB ## 10 N3ALAA ## # ... with 336,766 more rows # rename() does the same thing, except all columns not mentioned are kept flights %&gt;% rename(tail = tailnum) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;int&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tail &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;int&gt;, distance &lt;int&gt;, hour &lt;int&gt;, ## # minute &lt;int&gt;, time_hour &lt;chr&gt; 4.6.2 Choosing rows: filter, between, slice, sample_n, top_n, distinct filter() allows you to select a subset of rows in a data frame. Like all single verbs, the first argument is the tibble (or data frame). The second and subsequent arguments refer to variables within that data frame, selecting rows where the expression is TRUE. For example, we can select all flights on departed between 6:00 and 6:05 in the morning with: flights %&gt;% filter(dep_time &gt;= 600, dep_time &lt;= 605) ## # A tibble: 2,460 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 600 600 0 851 ## 2 2013 1 1 600 600 0 837 ## 3 2013 1 1 601 600 1 844 ## 4 2013 1 1 602 610 -8 812 ## 5 2013 1 1 602 605 -3 821 ## 6 2013 1 2 600 600 0 814 ## 7 2013 1 2 600 605 -5 751 ## 8 2013 1 2 600 600 0 819 ## 9 2013 1 2 600 600 0 846 ## 10 2013 1 2 600 600 0 737 ## # ... with 2,450 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;int&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;int&gt;, distance &lt;int&gt;, hour &lt;int&gt;, ## # minute &lt;int&gt;, time_hour &lt;chr&gt; # between() is a concise alternative for determing if numeric values fall in a range flights %&gt;% filter(between(dep_time, 600, 605)) # side note: is.na() can also be useful when filtering flights %&gt;% filter(!is.na(dep_time)) ## # A tibble: 328,521 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 328,511 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;int&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;int&gt;, distance &lt;int&gt;, hour &lt;int&gt;, ## # minute &lt;int&gt;, time_hour &lt;chr&gt; 4.6.3 Adding new variables: mutate, transmute, add_rownames Besides selecting sets of existing columns, it’s often useful to add new columns that are functions of existing columns. This is the job of mutate(): # mutate() creates a new variable (and keeps all existing variables) flights %&gt;% mutate(speed = distance/air_time*60) ## # A tibble: 336,776 x 20 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 13 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;int&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;int&gt;, distance &lt;int&gt;, hour &lt;int&gt;, ## # minute &lt;int&gt;, time_hour &lt;chr&gt;, speed &lt;dbl&gt; # transmute() only keeps the new variables flights %&gt;% transmute(speed = distance/air_time*60) ## # A tibble: 336,776 x 1 ## speed ## &lt;dbl&gt; ## 1 370. ## 2 374. ## 3 408. ## 4 517. ## 5 394. ## 6 288. ## 7 404. ## 8 259. ## 9 405. ## 10 319. ## # ... with 336,766 more rows # example data frame with row names mtcars %&gt;% head() ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # add_rownames() turns row names into an explicit variable mtcars %&gt;% add_rownames(&quot;model&quot;) %&gt;% head() ## Warning: Deprecated, use tibble::rownames_to_column() instead. ## # A tibble: 6 x 12 ## model mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Mazda~ 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 Mazda~ 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 Datsu~ 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 Horne~ 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 Horne~ 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 Valia~ 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 # side note: dplyr no longer prints row names (ever) for local data frames mtcars %&gt;% tbl_df() ## # A tibble: 32 x 11 ## mpg cyl disp hp drat wt qsec vs am gear carb ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # ... with 22 more rows 4.6.4 Grouping and counting: summarise, tally, count, group_size, n_groups, ungroup The verb summarise() collapses a data frame to a single row.It’s not that useful until chained with the group_by() verb below. # summarise() can be used to count the number of rows in each group flights %&gt;% group_by(month) %&gt;% summarise(cnt = n()) ## # A tibble: 12 x 2 ## month cnt ## &lt;int&gt; &lt;int&gt; ## 1 1 27004 ## 2 2 24951 ## 3 3 28834 ## 4 4 28330 ## 5 5 28796 ## 6 6 28243 ## 7 7 29425 ## 8 8 29327 ## 9 9 27574 ## 10 10 28889 ## 11 11 27268 ## 12 12 28135 # tally() and count() can do this more concisely flights %&gt;% group_by(month) %&gt;% tally() # you can sort by the count flights %&gt;% group_by(month) %&gt;% summarise(cnt = n()) %&gt;% arrange(desc(cnt)) ## # A tibble: 12 x 2 ## month cnt ## &lt;int&gt; &lt;int&gt; ## 1 7 29425 ## 2 8 29327 ## 3 10 28889 ## 4 3 28834 ## 5 5 28796 ## 6 4 28330 ## 7 6 28243 ## 8 12 28135 ## 9 9 27574 ## 10 11 27268 ## 11 1 27004 ## 12 2 24951 # you can sum over a specific variable instead of simply counting rows flights %&gt;% group_by(month) %&gt;% summarise(dist = sum(distance)) ## # A tibble: 12 x 2 ## month dist ## &lt;int&gt; &lt;int&gt; ## 1 1 27188805 ## 2 2 24975509 ## 3 3 29179636 ## 4 4 29427294 ## 5 5 29974128 ## 6 6 29856388 ## 7 7 31149199 ## 8 8 31149334 ## 9 9 28711426 ## 10 10 30012086 ## 11 11 28639718 ## 12 12 29954084 # tally() and count() have a wt parameter for this purpose flights %&gt;% group_by(month) %&gt;% tally(wt = distance) flights %&gt;% count(month, wt = distance) # group_size() returns the counts as a vector flights %&gt;% group_by(month) %&gt;% group_size() ## [1] 27004 24951 28834 28330 28796 28243 29425 29327 27574 28889 27268 ## [12] 28135 # n_groups() simply reports the number of groups flights %&gt;% group_by(month) %&gt;% n_groups() ## [1] 12 # group by two variables, summarise, arrange (output is possibly confusing) flights %&gt;% group_by(month, day) %&gt;% summarise(cnt = n()) %&gt;% arrange(desc(cnt)) %&gt;% print(n = 40) # A tibble: 365 x 3 # Groups: month [12] month day cnt &lt;int&gt; &lt;int&gt; &lt;int&gt; 1 11 27 1014 2 7 11 1006 3 7 8 1004 4 7 10 1004 5 12 2 1004 6 7 18 1003 7 7 25 1003 8 7 12 1002 9 7 9 1001 10 7 17 1001 11 7 31 1001 12 8 7 1001 13 8 8 1001 14 8 12 1001 15 7 22 1000 16 7 24 1000 17 8 1 1000 18 8 5 1000 19 8 15 1000 20 11 21 1000 21 7 15 999 22 7 19 999 23 7 26 999 24 7 29 999 25 8 2 999 26 8 9 999 27 11 22 999 28 8 16 998 29 7 23 997 30 7 30 997 31 8 14 997 32 7 16 996 33 8 6 996 34 8 19 996 35 9 13 996 36 9 26 996 37 9 27 996 38 4 15 995 39 6 20 995 40 6 26 995 # ... with 325 more rows # ungroup() before arranging to arrange across all groups flights %&gt;% group_by(month, day) %&gt;% summarise(cnt = n()) %&gt;% ungroup() %&gt;% arrange(desc(cnt)) # A tibble: 365 x 3 month day cnt &lt;int&gt; &lt;int&gt; &lt;int&gt; 1 11 27 1014 2 7 11 1006 3 7 8 1004 4 7 10 1004 5 12 2 1004 6 7 18 1003 7 7 25 1003 8 7 12 1002 9 7 9 1001 10 7 17 1001 # ... with 355 more rows References "],
["tidy.html", "Chapter 5 Reshaping data with tidyr 5.1 gather( ) function: 5.2 separate( ) function:", " Chapter 5 Reshaping data with tidyr It is often said that 80% of data analysis is spent on the cleaning and preparing data (Hadley and Grolemund 2016). And it’s not just a first step, but it must be repeated many times over the course of analysis as new problems come to light or new data is collected. Most of the time, our data is in the form of a data frame and we are interested in exploring the relationships(R Core Team 2018). However most procedures in R expect the data to show up in a ‘long’ format where each row is an observation and each column is a variable (Wickham and Henry 2018; Wickham et al. 2018). In practice, the data is often not stored like that and the data comes to us with repeated observations included on a single row. This is often done as a memory saving technique or because there is some structure in the data that makes the ‘wide’ format attractive. As a result, we need a way to convert data from wide5 to long6 and vice-versa (Matthew 2018). Data structure can become an issue when using statistical software packages, as some program prefer long format while others prefer wide format. For example, repeated-measures ANOVAs works with wide format, but between-subjects ANOVAs works well in long-format and mixed design ANOVAs work with both. dplyr, ggplot2, and all the other packages in the tidyverse for example work with long format data structure (Wickham 2017). In R, many of the statistics packages require the data to be in long-format (R Core Team 2018). It is important to become comfortable with either format, and with techniques for transforming data between formats. Therefore, the principles of tidy data provide a standard way to organise data values within a dataset either in long or wide format. And tidyr package was built for the sole purpose of simplifying the process of tranforming these two types of data structures depending on the requirement (Wickham and Henry 2018). This chapeter provides you with the basic understanding of the four fundamental functions of data tidying the data and structure it to format that make data analysis easy. These function include: gather() makes “wide” data longer spread() makes “long” data wider separate() splits a single column into multiple columns unite() combines multiple columns into a single column require(dplyr) require(readr) require(lubridate) require(readxl) require(haven) require(ggplot2) require(kableExtra) require(tidyr) 5.1 gather( ) function: There are times when our data is considered unstacked and a common attribute of concern is spread out across columns. To reformat the data such that these common attributes are gathered together as a single variable, the gather() function will take multiple columns and collapse them into key-value pairs, duplicating all other columns as needed. in short gather() function reshape wide format to long format (Figure 5.1) Figure 5.1: Reshaped data set from wide to long format The data in table 5.1 data is considered wide since the time variable (represented as quarters) is structured such that each quarter represents a variable. To re-structure the time component as an individual variable, we can gather each quarter within one column variable and also gather the values associated with each quarter in a second column variable. wide = read_table2(&quot;wide_data.txt&quot;) ## Parsed with column specification: ## cols( ## Group = col_integer(), ## Year = col_integer(), ## Qtr.1 = col_integer(), ## Qtr.2 = col_integer(), ## Qtr.3 = col_integer(), ## Qtr.4 = col_integer() ## ) wide %&gt;% kable(&quot;html&quot;, caption = &quot;Revenue data in Wide form&quot;)%&gt;% column_spec(column = 1:6, width = &quot;3cm&quot;, color = 1) %&gt;% add_header_above(c(&quot;&quot; , &quot;&quot;, &quot;Income per Quarter&quot; = 4), line = T) Table 5.1: Revenue data in Wide form Income per Quarter Group Year Qtr.1 Qtr.2 Qtr.3 Qtr.4 1 2006 15 16 19 17 1 2007 12 13 27 23 1 2008 22 22 24 20 1 2009 10 14 20 16 2 2006 12 13 25 18 2 2007 16 14 21 19 2 2008 13 11 29 15 2 2009 23 20 26 20 3 2006 11 12 22 16 3 2007 13 11 27 21 3 2008 17 12 23 19 3 2009 14 9 31 24 We use the gather() function to convert data in table 5.1 to long form widely known as indexed data shown in table 5.2 long = wide %&gt;% gather(key = &quot;key&quot;, value = &quot;Revenue&quot;, 3:6) Table 5.2: Revenue data in long form Group Year key Revenue 1 2006 Qtr.1 15 1 2007 Qtr.1 12 1 2008 Qtr.1 22 1 2009 Qtr.1 10 2 2006 Qtr.1 12 2 2007 Qtr.1 16 2 2008 Qtr.1 13 2 2009 Qtr.1 23 3 2006 Qtr.1 11 3 2007 Qtr.1 13 3 2008 Qtr.1 17 3 2009 Qtr.1 14 1 2006 Qtr.2 16 1 2007 Qtr.2 13 1 2008 Qtr.2 22 1 2009 Qtr.2 14 2 2006 Qtr.2 13 2 2007 Qtr.2 14 2 2008 Qtr.2 11 2 2009 Qtr.2 20 3 2006 Qtr.2 12 3 2007 Qtr.2 11 3 2008 Qtr.2 12 3 2009 Qtr.2 9 1 2006 Qtr.3 19 1 2007 Qtr.3 27 1 2008 Qtr.3 24 1 2009 Qtr.3 20 2 2006 Qtr.3 25 2 2007 Qtr.3 21 2 2008 Qtr.3 29 2 2009 Qtr.3 26 3 2006 Qtr.3 22 3 2007 Qtr.3 27 3 2008 Qtr.3 23 3 2009 Qtr.3 31 1 2006 Qtr.4 17 1 2007 Qtr.4 23 1 2008 Qtr.4 20 1 2009 Qtr.4 16 2 2006 Qtr.4 18 2 2007 Qtr.4 19 2 2008 Qtr.4 15 2 2009 Qtr.4 20 3 2006 Qtr.4 16 3 2007 Qtr.4 21 3 2008 Qtr.4 19 3 2009 Qtr.4 24 The spread() function is a complement functiongather()` as it convert long format dataset into wide form wide.wide = long %&gt;% spread(key = &quot;key&quot;, value = &quot;Revenue&quot;) 5.2 separate( ) function: Many times a single column variable will capture multiple variables, or even parts of a variable you just don’t care about. Examples include is data in table 5.3). usa = read_csv(&quot;separate.csv&quot;) ## Parsed with column specification: ## cols( ## Grp_Ind = col_character(), ## Yr_Mo = col_character(), ## City_State = col_character(), ## First_Last = col_character(), ## Extra_variable = col_character() ## ) Table 5.3: Messy data with variable combined Grp_Ind Yr_Mo City_State First_Last Extra_variable 1.a 2006_Jan Dayton (OH) George Washington XX01person_1 1.b 2006_Feb Grand Forks (ND) John Adams XX02person_2 1.c 2006_Mar Fargo (ND) Thomas Jefferson XX03person_3 2.a 2007_Jan Rochester (MN) James Madison XX04person_4 2.b 2007_Feb Dubuque (IA) James Monroe XX05person_5 2.c 2007_Mar Ft. Collins (CO) John Adams XX06person_6 3.a 2008_Jan Lake City (MN) Andrew Jackson XX07person_7 3.b 2008_Feb Rushford (MN) Martin Van Buren XX08person_8 3.c 2008_Mar Unknown William Harrison XX09person_9 In each of these cases, our objective may be to separate characters within the variable string. This can be accomplished using the separate() function which splits a single variable into multiple variables. Table 5.4 show the tidy data after the variables were separated. The complement function to separate() is the unite(), which merge two variables into one. usa.sep = usa %&gt;% separate(Grp_Ind, c(&quot;Group&quot;, &quot;Individual&quot;), remove = TRUE, convert = TRUE) %&gt;% separate(Yr_Mo, c(&quot;Year&quot;, &quot;Month&quot;), remove = TRUE, convert = TRUE) %&gt;% separate(City_State, c(&quot;City&quot;, &quot;State&quot;), remove = TRUE, convert = TRUE) %&gt;% separate(First_Last, c(&quot;First&quot;, &quot;Last&quot;), remove = TRUE, convert = TRUE) %&gt;% separate(Extra_variable, c(&quot;Extra&quot;, &quot;Variable&quot;), remove = TRUE, convert = TRUE) ## Warning: Expected 2 pieces. Additional pieces discarded in 8 rows [1, 2, 3, ## 4, 5, 6, 7, 8]. ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [9]. ## Warning: Expected 2 pieces. Additional pieces discarded in 1 rows [8]. Table 5.4: Tidy data with variable separated Group Individual Year Month City State First Last Extra Variable 1 a 2006 Jan Dayton OH George Washington XX01person 1 1 b 2006 Feb Grand Forks John Adams XX02person 2 1 c 2006 Mar Fargo ND Thomas Jefferson XX03person 3 2 a 2007 Jan Rochester MN James Madison XX04person 4 2 b 2007 Feb Dubuque IA James Monroe XX05person 5 2 c 2007 Mar Ft Collins John Adams XX06person 6 3 a 2008 Jan Lake City Andrew Jackson XX07person 7 3 b 2008 Feb Rushford MN Martin Van XX08person 8 3 c 2008 Mar Unknown NA William Harrison XX09person 9 References "],
["visualisation-with-ggplot.html", "Chapter 6 Visualisation with ggplot` 6.1 Univariate Distributions 6.2 Continuous Variables 6.3 Graphics with ggplot", " Chapter 6 Visualisation with ggplot` R provides numerous routines for displaying data as graphics. This chapter introduce the most important graphic functions. The graphics can be modified, printed, embedded in rmarkdown document or exported to be edited with graphic software outside R environment. There are three major “systems” of making graphs in R. The basic plotting commands in R are quite effective but the commands do not have a way of being combined in easy ways (R Core Team 2018). The simplest function producing a graph of a vector y versus another vector x is plot. First we create two vectors of x and y, where y is the sine of x x = seq(0,2*pi,pi/10) y = sin(x) length(y) ## [1] 21 These two command lines resulted into two vectors with 21 elements each. Since the two vector have the same length dimension, we can use plot() function to produce a 2D graph of y against x. The code produce figure 6.1 with an x-axis ranging from 0 ti 7 and a \\(y\\)-axis ranging from -1 to +1 and black line overlaid on point. plot(x,y, type = &quot;b&quot;, xlab = &quot;Independent variable&quot;, ylab = &quot;Dependent variable&quot;) Figure 6.1: Two dimension plot generated with base plot function We can even combine different plot in one layout with the combination of par() and mfrow() function. For example the code par(mfrow = c(1,3)) tell the computer to create container of one row that can accomodate three plots shown in figure 6.2 par(mfrow = c(1,3)) plot(x,y, type = &quot;p&quot;, xlab = &quot;Independent variable&quot;, ylab = &quot;Dependent variable&quot;) plot(x,y, type = &quot;l&quot;, xlab = &quot;Independent variable&quot;, ylab = &quot;Dependent variable&quot;) plot(x,y, type = &quot;b&quot;, pch = 8, cex = 2,col = 2 ,xlab = &quot;Independent variable&quot;, ylab = &quot;Dependent variable&quot;) Figure 6.2: Multiple plot in a single layout Lattice graphics (which the mosaic package uses) makes it possible to create some quite complicated graphs but it is very difficult to do make non-standard graphs (Sarkar 2008). The last package, ggplot2 tries to not anticipate what the user wants to do, but rather provide the mechanisms for pulling together different graphical concepts and the user gets to decide which elements to combine. The ggplot2 package, created by Hadley Wickham (2016), offers a powerful graphics language for creating elegant and complex plots. Its popularity in the R community has exploded in recent years. Originally based on Leland Wilkinson’s The Grammar of Graphics (2006), ggplot2 allows you to create graphs that represent both univariate and multivariate numerical and categorical data in a straightforward manner. Unfortunate ggplot2 works only with data that are in data frame. If we want to plot the x and y variables we just created, we need to store them in the data frame first for ggplot to draw the graph (Wickham 2017). We first load the package we need to work with for this chapter into the working directory. I am working a R project and defined the path of the working directory. Make sure you have also specified the path of the working directory. You can check section 2.3 that illustrats how to set a working directory in R. The default ggplot2 draw a plot with a gray background like the one shown in figure 6.3. We will discuss on how to change and customize plot made with ggplot2, but for now we may focus on the tools of making and draw plot with these package. Once we are familiar with its syntax, we can expand the skills by touching on issue related to creating quality publication plots with ggplot. y2 = cos(x) x.ys = data.frame(x,y,y2) ggplot(data = x.ys, aes(x = x, y = y)) + geom_point() + geom_line() Figure 6.3: Sine plot with ggplot2 Sometimes We may wish to plot two different in one plot. That happen when you have two or more dependent variables and one independent variable. We need to create a second y variable and a cosine of xcan suits well for illustration. x = seq(0,2*pi,pi/10) y = sin(x) y2 = cos(x) x.ys = data.frame(x,y,y2) Figure 6.4 show the cosine and sine curves, unfortunately you can not distinguish them because the legend is missing. Here comes the problem inherited with untidy data discussed in chapter 5. Alghout the data is the data frame and ggplot2 can plot them, the data frame is untidy and therefore can not draw the lines with their respective legend. we therefore need to tidy the data and first and replot. ggplot(data = x.ys) + geom_line(aes(x = x, y = y), col = &quot;red&quot;, show.legend = TRUE)+ geom_point(aes(x = x, y = y), col = &quot;red&quot;) + geom_line(aes(x = x, y = y2), col = &quot;blue&quot;, show.legend = TRUE)+ geom_point(aes(x = x, y = y2), col = &quot;blue&quot;) Figure 6.4: Two dependent variables plotted in one independent variable We first need to transform the data frame from wide to long format with gather() function of tidyr package. Because the x variable is the same for the two ys, we transform the variable y and y2 x.ys.long = x.ys %&gt;% tidyr::gather(key = &quot;ys&quot;, value = &quot;values&quot;, 2:3) Once the data is tidy, plotting and define the color makes easy for ggplot to distinguish and label the variables with a legend as shown in figure 6.5 ggplot(data = x.ys.long, aes(x = x, y = values, col = ys))+geom_line() + geom_point()+ theme(legend.position = &quot;top&quot;) + scale_colour_manual(values = c(&quot;red&quot;, &quot;blue&quot;), name = NULL) Figure 6.5: Two dependent variables plotted in one independent variable with legend 6.1 Univariate Distributions Before moving on to more sophisticated visualizations that enable multidimensional investigation, it is important to be able to understand how an individual variable is distributed. Visually understanding the distribution allows us to describe many features of a variable. 6.2 Continuous Variables A variable is continuous if it can take any of an infinite set of ordered values. There are several different plots that can effectively communicate the different features of continuous variables. Features we are generally interested in include: Measures of location Measures of spread Asymmetry Outliers Gaps Hadley Wickham in his book Elegant Graphics for Data Analysis with ggplot clearly said ggplot2 is designed to act on data frames (Wickham 2016). It is actually hard to just draw three data points and for simple graphs it might be easier to use the base graphing system in R. Fortunate ggplot2 makes plotting easy because of its large number of basic building blocks that, when stacked upon each other, can produce extremely complicated graphs. A full list is available at http://docs.ggplot2.org/current/. In summary, we can break the art of making graph with ggplot2 three main steps. Understand the type of data you are going to use Ask yourself what is the major relationship we wish to examine? Choose the appropriate graph that suits your data. We will use the audit dataset in table 6.1 to illustrate how to use ggplot2 package to make elegant graphics in R. We chopped this dataset from the rattle package. The audit dataset is an artificially constructed dataset that has some of the characteristics of a true financial audit datase (Maindonald 2012) Table 6.1: Individual Auditing Infomration ID Age Employment Education Marital Occupation Income Gender 6260817 21 Private College Absent Service 119419.36 Male 8511774 50 Private Associate Divorced Repair 87361.20 Male 4527269 36 Private Bachelor Married Support 34606.74 Male 3718723 66 Private HSgrad Widowed Sales 96057.04 Female 4516220 48 Private Bachelor Married Support 113867.76 Female 1158519 45 Private Vocational Married Repair 26717.49 Male 7488134 45 PSLocal Master Absent Professional 54304.38 Female 9717671 53 Consultant HSgrad Married Executive 37678.12 Male 5806158 34 Consultant College Divorced Clerical 201606.08 Female 7219320 25 NA Bachelor Married NA 46429.12 Male 6.3 Graphics with ggplot 6.3.1 Categorical Data 6.3.1.1 Barplot The ggplot() function only needs to specify the data and aes. Note the unusual use of the plus sign “+” to add the effect of of geom_bar() to ggplot(). Only one variable plays an aesthetic role: workshop. The aes() function sets that role. To produce figure 6.6 you can write the code below: ggplot(data = audit, aes(x = Education))+ geom_bar() Figure 6.6: Barplot of frequency of people with various education level Figure 6.6 plot some of the education that are of no interest to us, we can limit the education level by adding a limits function in the scale_x_discrete() function to produce figure 6.7. The code for figure 6.7 is: ggplot(data = audit, aes(x = Education))+ geom_bar() + scale_x_discrete(limits = c(&quot;Preschool&quot;, &quot;Vocational&quot;, &quot;College&quot;,&quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctorate&quot;)) Figure 6.7: Barplot of frequency of people in six education level If you want to fill the bars with color (Figure 6.8), you can parsethe fill argument in geom_bar(). ggplot(data = audit, aes(x = Education))+ geom_bar(fill = c(&quot;red&quot;, &quot;purple&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;maroon&quot;, &quot;pink&quot;)) + scale_x_discrete(limits = c(&quot;Preschool&quot;, &quot;Vocational&quot;, &quot;College&quot;,&quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctorate&quot;)) Figure 6.8: Barplot of frequency of people in six education level The use of color in figure 6.8 was, well, colorful, but it did not add any useful information. However, when displaying bar plots of six education level, the fill argument with Gender very useful. Figure 6.9 I use fill to color the bars by gender and set the “position” to stack. ggplot(data = audit, aes(x = Education))+ geom_bar(aes(fill = Gender), position = &quot;stack&quot;) + scale_x_discrete(limits = c(&quot;Preschool&quot;, &quot;Vocational&quot;, &quot;College&quot;,&quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctorate&quot;)) Figure 6.9: Barplot of frequency of people in six education level Figure 6.10 is similar to figure 6.9, changing only the bar position to be dodge. ggplot(data = audit, aes(x = Education))+ geom_bar(aes(fill = Gender), position = &quot;dodge&quot;) + scale_x_discrete(limits = c(&quot;Preschool&quot;, &quot;Vocational&quot;, &quot;College&quot;,&quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctorate&quot;)) Figure 6.10: Barplot of frequency of people in six education level 6.3.1.2 Pre-summarized Data The geom_bar() function summarizes data for you. If it is already summarized, you use geom_col() instead. The chunk below summarize the eduction level and then plot the summarized result in figure 6.11. education = audit %&gt;% filter(Education %in% c(&quot;Preschool&quot;, &quot;Vocational&quot;, &quot;College&quot;,&quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctorate&quot;)) %&gt;% group_by(Education) %&gt;% summarise(Count = n()) ggplot(data = education, aes(x = Education, y = Count))+geom_col()+ scale_x_discrete(limits = c(&quot;Preschool&quot;, &quot;Vocational&quot;, &quot;College&quot;,&quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctorate&quot;)) Figure 6.11: Barplot of frequency of people in six education level 6.3.2 Numerical Data 6.3.2.1 Histograms Histograms are often overlooked, yet they are a very efficient means for communicating distribution of continuous variables. geom_histogram() is used to make histogram in ggplot2 package. Figure 6.12 was created using the code in the chunk below: ggplot(data = audit, aes(x = Age)) + geom_histogram() Figure 6.12: Age distribution labs() function is used in ggplot2 to add annotations in plot as in figure 6.13. ggplot(data = audit%&gt;% filter(Education %in% c(&quot;Preschool&quot;, &quot;Vocational&quot;, &quot;College&quot;,&quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctorate&quot;)), aes(x = Age)) + geom_histogram()+ labs(x = &quot;Age of Individuals&quot;, y = &quot;Number of Individuals&quot;, title = &quot;The Age of Individuals audited in US&quot;, subtitle = &quot;The audit was done to 2000 individuals aiming to illustrate the auditing&quot;) Figure 6.13: Age distribution facet_wrap() function is used in ggplot2 to make multiple plots in a single layout as illustrated n figure 6.14. ggplot(data = audit%&gt;% filter(Education %in% c(&quot;Preschool&quot;, &quot;Vocational&quot;, &quot;College&quot;,&quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctorate&quot;)), aes(x = Age)) + geom_histogram()+ labs(x = &quot;Age of Individuals&quot;, y = &quot;Number of Individuals&quot;) + facet_wrap(~Education, scales = &quot;free_y&quot;) Figure 6.14: Age distribution grouped by education level References "],
["adding-equations-to-your-document.html", "Chapter 7 Adding Equations to Your Document 7.1 Subscripts and Superscripts 7.2 Square Roots 7.3 Fractions 7.4 Summation Expressions 7.5 Greek Letters 7.6 Special Symbols 7.7 Special Functions 7.8 Mathematical equations. 7.9 The binomial probability: 7.10 Aligning Equations with Comments", " Chapter 7 Adding Equations to Your Document 7.1 Subscripts and Superscripts To indicate a subscript, use the underscore _ character. To indicate a superscript, use a single caret character ^. Note: this can be confusing, because the R Markdown language delimits superscripts with two carets. In LaTeX equations, a single caret indicates the superscript. If the subscript or superscript has just one character, there is no need to delimit with braces. However, if there is more than one character, braces must be used. The following examples illustrate: $X_i$ display as \\(X_i\\) and this LaTeX form$X_{i}$ display as \\(X_{i}\\) Notice that in the above case, braces were not actually needed. In this next example, however, failure to use braces creates an error, as LaTeX sets only the first character as a subscript $X_{i,j}$ display as \\(X_{i,j}\\) and $X_i,j$ diaplay as \\(X_i,j\\) This expression $X^2_{i,j}$ which display as \\(X^2_{i,j}\\) that uses both subscripts and superscripts 7.2 Square Roots This expression $\\sqrt{b^2 - 4ac}$ display \\(\\sqrt{b^2 - 4ac}\\) . We indicate a square root using the \\sqrt operator. 7.3 Fractions Displayed fractions are typeset using the \\frac operator. for instance, this expression $\\frac{4z^3}{16}$ display as \\(\\frac{4z^3}{16}\\) 7.4 Summation Expressions These are indicated with the \\(\\sum\\) operator, followed by a subscript for the material appearing below the summation sign, and a superscript for any material appearing above the summation sign. Example, this expression $\\sum_{i=1}^{n} X^3_i$ display as \\(\\sum_{i=1}^{n} X^3_i\\) 7.5 Greek Letters Many statistical expressions use Greek letters. Much of the Greek alphabet is implemented in LaTeX, as indicated in the LaTeX cheat sheet available at the course website. There are both upper and lower case versions available for some letters. for instance, $\\alpha, \\beta, \\gamma, \\Gamma$ displays as \\(\\alpha, \\beta, \\gamma, \\Gamma\\) 7.6 Special Symbols All common mathematical symbols are implemented, and you can find a listing on the LaTeX cheat sheet.Some examples. (Notice that, in the third example, I use the tilde character for a forced space. Generally LaTeX does spacing for you automatically, and unless you use the tilde character, R will ignore your attempts to add spaces.). This expression $a \\pm b$ display as \\(a \\pm b\\), $x \\ge 15$ displays as \\(x \\ge 15\\); $a_i \\ge 0~~~\\forall i$show as \\(a_i \\ge 0~~~\\forall i\\); and $x \\le 15$ show as \\(x \\le 15\\). 7.7 Special Functions LaTeX typesets special functions in a different font from mathematical variables. These functions, such as sin, cos , etc. are indicated in LaTeX with a backslash. This expression $\\int_0^{2\\pi} \\sin x~dx$ which appear as \\(\\int_0^{2\\pi} \\sin x~dx\\) illustrates how to typeset an integral. 7.8 Mathematical equations. compute the variance , average and standard deviation of a set of vector. The average of a vector is \\(\\bar{x} = \\sum \\frac{x_i}{n}\\), where \\(\\sum x_i = x_1 + _\\cdots + x_n\\) is the sum of the input values. The standard deviation expressed below appear as mathematical equation (7.1) $$ \\begin{equation} s = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}} (\\#eq:eqn2) \\end{equation} $$ Appear as \\[ \\begin{equation} s = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}}\\tag{7.1} \\end{equation} \\] However, equation (7.1) is not suitable for the task. Because by the time \\(\\bar{x}\\) is computed, the individual \\(x_i\\) are gone. Alternatively is to use the equation (7.2), which compute the quantity by keeping track of the count, sum, and sum of the squares as the input values are processed. $$ \\begin{equation} s = \\sqrt\\frac{\\sum x_{i}^2 - \\frac{1}{n}(\\sum x_i)^2}{n - 1}(\\#eq:eqn3) \\end{equation} $$ \\[ \\begin{equation} s = \\sqrt\\frac{\\sum x_{i}^2 - \\frac{1}{n}(\\sum x_i)^2}{n - 1}\\tag{7.2} \\end{equation} \\] 7.9 The binomial probability: The binomial probability in equation (7.3) is mathematically expressed as$$ \\begin{equation} f(y|N,p) = \\frac{N!}{y!(N-y)!}\\cdot p^y \\cdot (1-p)^{N-y} = {{N}\\choose{y}} \\cdot p^y \\cdot (1-p)^{N-y} (\\#eq:eqn4) \\end{equation} $$ \\[ \\begin{equation} f(y|N,p) = \\frac{N!}{y!(N-y)!}\\cdot p^y \\cdot (1-p)^{N-y} = {{N}\\choose{y}} \\cdot p^y \\cdot (1-p)^{N-y} \\tag{7.3} \\end{equation} \\] The expression $$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_{i}$$ calculate the mean of observations of variable , as shown in equation (7.4): \\[ \\begin{equation} \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_{i} \\tag{7.4} \\end{equation} \\] The equation for computing variance (equation (7.5)) is expressed mathematically as $\\sigma^{2} = \\frac{\\sum\\limits_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)^{2}} {n-1}$ \\[ \\begin{equation} \\sigma^{2} = \\frac{\\sum_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)^{2}} {n-1} \\tag{7.5} \\end{equation} \\] Next, the equation for computing covariance (equation (7.7)) is expressed mathematically as $\\begin{equation}cov_{x,y} = \\frac{\\sum\\limits_{i=1}^{n}{(x_i-\\overline{x}) \\cdot (y_i-\\overline{y})} }{n-1} \\tag{7.6}\\end{equation}$ \\[ \\begin{equation} cov_{x,y} = \\frac{\\sum\\limits_{i=1}^{n}{(x_i-\\overline{x}) \\cdot (y_i-\\overline{y})} }{n-1} \\tag{7.7} \\end{equation} \\] And, then, the equation for computing standard deviation (equation (7.8)) is expressed mathematically as $\\sigma = \\sqrt{\\frac{\\sum\\limits_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)^{2}} {n-1}} (\\#eq:eqn8)$ \\[ \\begin{equation} \\sigma = \\sqrt{\\frac{\\sum\\limits_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)^{2}} {n-1}} \\tag{7.8} \\end{equation} \\] There are helpful online editors to help you learn code for various equations you might want to include. I have found the one at: http://visualmatheditor.equatheque.net/VisualMathEditor.html to be very useful. You can work out the code there and then copy it over to your RMarkdown document in between dollar signs (1 or 2 on either end depending on whether you want the equation in line or in display mode). Right Left Default Center 12 12 12 12 123 123 123 123 1 1 1 1 7.10 Aligning Equations with Comments In proving a result, it is often useful to include comments. Here is an expression showing how you can do that. $$ \\begin{align} 3+x &amp;=4 &amp;&amp; \\text{(Solve for} x \\text{.)}\\\\ x &amp;=4-3 &amp;&amp; \\text{(Subtract 3 from both sides.)}\\\\ x &amp;=1 &amp;&amp; \\text{(Yielding the solution.)} \\end{align} $$ ` Result into \\[ \\begin{align} 3+x &amp;=4 &amp;&amp; \\text{(Solve for} x \\text{.)}\\\\ x &amp;=4-3 &amp;&amp; \\text{(Subtract 3 from both sides.)}\\\\ x &amp;=1 &amp;&amp; \\text{(Yielding the solution.)} \\end{align} \\] In Acts 20:35 Paul quoted Jesus when he said: it is better to give than to receive! "],
["univariate-statistics.html", "Chapter 8 Univariate Statistics 8.1 Introduction 8.2 Empical Distributions", " Chapter 8 Univariate Statistics 8.1 Introduction Statistical properties of a single parameter are invegated by means of univariate analysis. Such a parameter could, for example be the the size of population, the the gross domestic product (GDP) of the country in the world or life expactancy of the country. Because in most cases the data we collect depend on the sample size that are often limited because of either financial or logistic constraints. The method of univariate statistics assist us to draw from the sample conclusions that apply to the population as whole (Trauth 2015). R contains myriad of tools for statistical analysis. We will use the base package stats with other extended packages to illustrate concept of univariate statistics (R Core Team 2018). 8.2 Empical Distributions Let us assume that we have collected a number of measurement of \\(x_i\\) from a specific area. The collection of data, or sample, as a subset of the population of interest can be writeen as a vector of \\(x\\) containing a total of \\(N\\) observations mathematically in equation (8.1). The vector \\(x\\) may contain a large number of data points and it may conseuently be difficult to understand its properties. Descriptive statists are therefore often used to summarize the characteristics of the data. THe statistical properties of the data set may be used to define an empirical distribution, which can then be compared to a theoretical one. \\[ \\begin{equation} x = (x_1, x_2, \\dots, x_n) \\tag{8.1} \\end{equation} \\] The most straightfoward way of investigating the sample characteristics is to plot the data graphically. Plotting all the data points along a single axis does nto reveal a great deal of information about the dat set. However, the density of the points along the scale does provide some information about the characteristics of the data. A widely used graphical display of continous univariate variable is the histogram7. Histogram provide vital information on the characteristics of the data like the central tendency, the dispersion and general shape of the distribution of quantitative data (Figure 8.1. In general term, the central tendency parameters—the mean and median define the center of the dataset, while the range and standard deviation provide information of how the data deviate from the center. Figure 8.1: Emprical distribution of the frequency of quantitatively data 8.2.1 Measure of Central Tendency The median and mean are parameters of central tendency or location represent the most important measure for describing emperical distribution of quantitative data. These parameters help locate the data on a linear scale. They represent a typical or best value that describe the data. The most most popular indicator of central tendency is the arithmetic mean, which is the sum of all data points divided by the total number of observations. The *arithmetic mean can be computed with equation (8.2) \\[ \\begin{equation} \\bar x = \\frac{1}{N}\\sum_{i=1}^N x_i \\tag{8.2} \\end{equation} \\] The arithmetic mean is also called mean or the average of a unvariate variable. The sample mean is used as an estimate of the population mean \\(\\mu\\) for the underlying theoretical distribution. The arithmetric mean is, however, sensitive to outlier—extreme values that may be very dfferent from the majoriy of the data, hence median is often used an an alternative measured of central tendency. The median is the \\(x\\)-value that is in the middle of the variable, i.e 50% of the observations are smaller than the median and 50% are larger (Trauth 2015). The median of a quantitative data sorted in ascending order is mathematically written as equation (8.3) if \\(N\\) is odd; and equation (8.4) if \\(N\\) is even. \\[ \\begin{equation} X = x_{(N+1)/2} \\tag{8.3} \\end{equation} \\] \\[ \\begin{equation} X =x_{N/2} + x_{(N+1)/2} \\tag{8.4} \\end{equation} \\] The third important measure for central tendeny is the mode. The mode is the most frequent \\(x\\)-value. Or for the grouped data, the the ccenter is the class with the largest number of observations. If the data values in the variable are unique that datase will have no mode. Frequency distribution with a single mode are called unimodla, but there variables with two modes(bimodal), three modes(trimodal) or four or more modes (multimodal) (Figure 8.2) Figure 8.2: Dispersion and shape of distribution, a-b) unimodal distribution showing a negative or positive skew, c-d) distribution showing a high or low kurtosis, e-f) bimodal and trimodal distribution showing two or more modes. Source (Trauth 2015) The mean, median, and mode are used when several quantities add together to produce a total, wherea the geometric mean is often used if these quantities are multiplied. Let us assume that the economy of country \\(x\\) increases by 10% the first year, 25% in the second year , and 60% in the last year. The average rate of increase is not the arithmetic mean, because the original number of individual has increase by a factor (not sum) of 1.1 after one year, 1.25 after the second year and r160/100 after the third year. The average growth of the economy is therefore calculated by the geometric mean with equation (8.5) \\[ \\begin{equation} \\bar x_g = (x_1 \\times x_2 \\times \\dots x_n)^\\frac{1}{N} \\tag{8.5} \\end{equation} \\] The average growth of these values is 1.3006 suggesting an approximate per annum growth in the economy of 30%. The arithmetic mean would result in an errenous value of 1.3167 of approximately 32% annual growth. The geometric mean is also a sueful mesure of central tendency for skewed or log-normal distributed data, in which the logarithms of the observation follow a Gausian or normal distribution. The geomeric mean, however, s not used for variables containing negative values. The last is the harmonic mean used to derive a mean value for asymetric or log-normal distributed data similar to geometric mean. Unfortunate, the harmonic mean is sensitive to outlier. The harmonic mean is a better average when values are defined in relation to a particular unt. A commonly quoted example is averging velocity. The harmonic mean is also used to compute the mean of the sample sizes. The equation (8.6) is used to compute harmonic mean. \\[ \\begin{equation} \\bar x_H =\\frac{N}{(\\frac{1}{x_1} + \\frac{1}{x_2} + \\dots +\\frac{1}{x_N})} \\tag{8.6} \\end{equation} \\] 8.2.2 Measure of Dispersion A second important component of the distribution is the dispersion. Some of the parameters that can be used to quantify dispersion are illustrated in figure 8.2. The simplest way to describe the dispersion of a dat ase is by the range— a difference between the highest and the lowest value in the quantitative data. The range can be computed with equation (8.7) \\[ \\begin{equation} \\delta x = X_{max} - X_{min} \\tag{8.7} \\end{equation} \\] Since the range is defined by the two extreme data points it is very susceptible to outliers and hence it is not a reliable measure of dispersion in most cases. Using the interquantile range of data—the middle 50% of the data attempt to overcome this problem. The widely used measure for dispersion is the standard deviation—the average deviation of each data point from the mean. The standard deviation of sample in an emprical distribution is often used as an estimate of the population standard deviation \\(\\sigma\\) equation (8.8) \\[ \\begin{equation} s = \\sqrt {\\frac{\\sum \\limits_{i=1}^N (x_i - \\bar x)}{N-1}} \\tag{8.8} \\end{equation} \\] The s formula for the poulation standard deviation uses \\(N\\) instead of \\(N-1\\) as the denominator. The sample standard deviation \\(s\\) is computed with \\(N-1\\) instead of \\(N\\) since it uses the sample mean instead of the unknown population mean. The sample mean, however, is computed from the data \\(x_p\\) which reduce the number of degrees of freedom by one. The degree of freedom are number of values in a distribution that are free to be varied. Dividing the average deviation of the data from the mean by \\(N\\) would therefore underestimate the population standard deviation \\(\\sigma\\). The variance is the third important measure of dispersion. The variance is the square of the standard deviation equation (8.9). \\[ \\begin{equation} s^{2} = \\frac{\\sum\\limits_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)^{2}} {n-1} \\tag{8.9} \\end{equation} \\] Although the variance has the disadvantage of mismatch dimension with original data, it is extensively used in many applications than the standard deviation. Other measure of distribution are skewness and kurtosis that are used to describe the shape of a frequency distribution (Fig). Skewness is a measure of the asymmetry of the tails of a distribution. A negative skew indicates the distribution is spread out more to the left of the mean value, assuming values increasing towards the right along the axis. Distribution with positive skewness have large tails that extend toward the right. Although Pearson’ formular for measure skewness is useful, the Fisher formular in equation (8.10) is used instead \\[ \\begin{equation} skewness = \\sum\\limits_{i=1}^{n} {\\frac{(x_i - \\bar x)^3}{s^3}}\\tag{8.10} \\end{equation} \\] The second important measure of the shape of a distribution is the kurtosis that can be computed with a formulae in equation (8.11). Kurtosis measure whether the data are peaked or flat relative to a normal distribution. A high kurtosis indicates that the distribution has a distinct peak near the mean, whereas a low kurtosis shows a flat top near the mean and broad tails. Higher peakedness in a distribution results from rare extreme deviations, whereas low kurtosis is caused by frequent moderate deviations. A normal distribution has a kurtosis of three, and some definitions therefore substract three from the above term in order to set the kurtois of the normal distribution to zero. \\[ \\begin{equation} kurtosis = \\sum\\limits_{i=1}^{n} {\\frac{(x_i - \\bar x)^4}{s^4}}\\tag{8.11} \\end{equation} \\] . References "],
["bivariate.html", "Chapter 9 Bivariate", " Chapter 9 Bivariate Bivariate analysis aims to understand the relationship between two variables, x and y. Examples are the length and width of a fossil, the sodium and potassium content of volcanic glass, and the organic matter content along a sediment core. When the two variables are measured on the same object, x is usually identifi ed as the independent variable and y as the dependent variable. If both variables have been generated in an experiment, the variable manipulated by the experimenter is described as the independent variable. In some cases neither variable is manipulated and neither is independent. "],
["references.html", "References", " References "]
]
